from datetime import datetime
from pydantic import BaseModel
from typing import Dict

from app.api.utils import get_coordinates_from_address, find_nearest_stop, verify_stop_exists
from app.api.config import openai_client
from app.api.trip import get_trip, TripRequestModel


# Dictionnaire pour stocker les conversations en cours
conversations: Dict[str, Dict] = {}


class UserQuery(BaseModel):
    '''
    ModÃ¨le de donnÃ©es pour les requÃªtes utilisateur
    '''
    query: str
    session_id: str


def initialize_conversation(session_id: str):
    """
    Initialise une nouvelle conversation avec un message de bienvenue
    """
    conversations[session_id] = {
        "steps": {
            "origin": None,
            "destination": None,
            "date": None,
            "time": None,
        },
        "conversation_history": [
            {"role": "assistant", "content": "Bonjour, je suis votre assistant virtuel des transports publics Suisse (TP-Suisse). ğŸš‚ğŸšŒğŸš‹â›´ï¸\nPour connaÃ®tre le nom exact d'un arrÃªt, veuillez cliquer sur la bulle de chat ci-dessous. ğŸ’¬\n Pour arrÃªter/recommencer la conversation, Ã©crivez 'STOP' ou rafrachissez la page. ğŸ›‘\nOÃ¹ desirez-vous aller ? ğŸŒ"}
        ],
        "count_trip_details": 0
    }


def generate_response(conversation_history, prompt, max_tokens=150):
    """
    GÃ©nÃ¨re une rÃ©ponse en utilisant GPT
    """
    gpt_response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=conversation_history + [{"role": "user", "content": prompt}],
        max_tokens=max_tokens,
        temperature=0.7
    )
    return gpt_response.choices[0].message.content.strip()


def handle_conversation_steps(user_input, steps, conversation_history):
    """
    GÃ¨re les diffÃ©rentes Ã©tapes de la conversation en fonction des informations fournies par l'utilisateur
    """
    if not steps["destination"] or steps["destination"] is None:
        return process_destination_step(user_input, steps, conversation_history)

    if not steps["origin"] or steps["origin"] is None:
        return process_origin_step(user_input, steps, conversation_history)

    if not steps["date"] or not steps["time"] or steps["date"] is None or steps["time"] is None:
        return process_date_time_step(user_input, steps, conversation_history)


def process_destination_step(user_input, steps, conversation_history):
    """
    Traite l'Ã©tape oÃ¹ l'utilisateur spÃ©cifie sa destination
    """
    gpt_help = generate_response(conversation_history, f"L'utilisateur a surement mentionnÃ© une destination dans {user_input}. Met l'arret entre deux # pour l'extraire. Souvent, il y a le nom de la ville ou commune virgule puis l'arrÃªt : #Ville, ArrÃªt#. Apart ce qu'il y a entre les #, tu peux ignorer le reste. Si tu penses que c'est une adresse, un monument ou un lieu spÃ©cifique, tu mets le maximum d'informations pour trouver l'arrÃªt le plus proche (surtout la ville ou commune) sans oublier les # mais pas besoin de structure spÃ©cifique comme pour l'arret : #Ville, ArrÃªt#.")
    if "#" in gpt_help:
        stop_name = gpt_help.split("#")[1]
        verified_stop = verify_stop_exists(stop_name)
        if verified_stop:
            steps["destination"] = verified_stop
            return generate_response(conversation_history, f"L'utilisateur a mentionnÃ© {verified_stop} comme destination. Formule une rÃ©ponse pour informer que l'arrÃªt est sÃ©lectionnÃ© et enchainer la suite de la conversation avec le point de dÃ©part.")
        else:
            coordinates = get_coordinates_from_address(stop_name)
            if coordinates:
                nearest_stop = find_nearest_stop(*coordinates)
                if nearest_stop is not None:
                    steps["destination"] = nearest_stop
                    return generate_response(conversation_history, f"L'utilisateur a mentionnÃ© {stop_name} comme destination. Je n'ai pas trouvÃ© l'arrÃªt exact directement, mais j'ai trouvÃ© l'arrÃªt le plus proche: {nearest_stop} grÃ¢ce Ã  une recherche des coordonnÃ©es. Formule une rÃ©ponse pour informer que l'arrÃªt est sÃ©lectionnÃ© et enchainer la suite de la conversation avec le point de dÃ©part.")
                else:
                    return generate_response(conversation_history, "La destination mentionnÃ©e par l'utilisateur n'a pas Ã©tÃ© trouvÃ©e malgrÃ© une recherche des coordonnÃ©es. Demande-lui de prÃ©ciser, d'utiliser la bulle de chat pour trouver l'arrÃªt exact ou de rÃ©essayer avec un autre arrÃªt.")
            else:
                return generate_response(conversation_history, "L'utilisateur a mentionnÃ© une destination que je n'ai pas trouvÃ©e. Demande-lui de prÃ©ciser, d'utiliser la bulle de chat pour trouver l'arrÃªt exact ou de rÃ©essayer avec un autre arrÃªt.")
    else:
        return generate_response(conversation_history, "L'utilisateur a mentionnÃ© une destination que je n'ai pas trouvÃ©e. Demande-lui de prÃ©ciser ou de rÃ©essayer avec un autre arrÃªt pour la destination afin de continuer.")


def process_origin_step(user_input, steps, conversation_history):
    """
    Traite l'Ã©tape oÃ¹ l'utilisateur spÃ©cifie son point de dÃ©part
    """
    gpt_help = generate_response(conversation_history, f"L'utilisateur a surement mentionnÃ© un point de dÃ©part dans {user_input}. Met l'arret entre deux # pour l'extraire. Souvent, il y a le nom de la ville ou commune virgule puis l'arrÃªt : #Ville, ArrÃªt#. Apart ce qu'il y a entre les #, tu peux ignorer le reste. Si tu penses que c'est une adresse, un monument ou un lieu spÃ©cifique, tu mets le maximum d'informations pour trouver l'arrÃªt le plus proche (surtout la ville ou commune) sans oublier les # mais pas besoin de structure spÃ©cifique comme pour l'arret : #Ville, ArrÃªt#.")
    if "#" in gpt_help:
        stop_name = gpt_help.split("#")[1]
        verified_stop = verify_stop_exists(stop_name)
        if verified_stop:
            steps["origin"] = verified_stop
            return generate_response(conversation_history, f"L'utilisateur a mentionnÃ© {verified_stop} comme point de dÃ©part. Formule une rÃ©ponse pour informer que l'arrÃªt est sÃ©lectionnÃ© et demander la date et l'heure.")
        else:
            coordinates = get_coordinates_from_address(stop_name)
            if coordinates:
                nearest_stop = find_nearest_stop(*coordinates)
                if nearest_stop is not None:
                    steps["origin"] = nearest_stop
                    return generate_response(conversation_history, f"L'utilisateur a mentionnÃ© {stop_name} comme point de dÃ©part. Je n'ai pas trouvÃ© l'arrÃªt exact directement, mais j'ai trouvÃ© l'arrÃªt le plus proche: {nearest_stop} grÃ¢ce Ã  une recherche des coordonnÃ©es. Formule une rÃ©ponse pour informer que l'arrÃªt est sÃ©lectionnÃ© et demander la date et l'heure.")
                else:
                    return generate_response(conversation_history, "L'utilisateur a mentionnÃ© un arrÃªt de dÃ©part que je n'ai pas trouvÃ© malgrÃ© une recherche des coordonnÃ©es. Demande-lui de prÃ©ciser, d'utiliser la bulle de chat pour trouver l'arrÃªt exact ou de rÃ©essayer avec un autre arrÃªt.")
            else:
                return generate_response(conversation_history, "L'utilisateur a mentionnÃ© un arrÃªt de dÃ©part que je n'ai pas trouvÃ©. Demande-lui de prÃ©ciser, d'utiliser la bulle de chat pour trouver l'arrÃªt exact ou de rÃ©essayer avec un autre arrÃªt.")
    else:
        return generate_response(conversation_history, "L'utilisateur a mentionnÃ© un arrÃªt de dÃ©part que je n'ai pas trouvÃ©. Demande-lui de prÃ©ciser ou de rÃ©essayer avec un autre arrÃªt.")


def process_date_time_step(user_input, steps, conversation_history):
    """
    Traite l'Ã©tape oÃ¹ l'utilisateur spÃ©cifie la date et l'heure
    """
    gpt_help = generate_response(conversation_history, f"L'utilisateur a mentionnÃ© une date et une heure dans '{user_input}'. Pour information, la date du jour est {datetime.now().strftime('%Y-%m-%d')} et l'heure est {datetime.now().strftime('%H:%M:%S')}. Met la date entre deux # pour l'extraire et l'heure entre deux $. Tu peux Ã©crire seulement la date et/ou l'heure, pas besoin d'autres informations. Le format de la date est 'YYYY-MM-DD' et l'heure 'HH:MM:SS'.")

    # Extraire date et heure selon les dÃ©limiteurs '#' et '$'
    date_str = None
    time_str = None

    if "#" in gpt_help:
        date_str = gpt_help.split("#")[1]

    if "$" in gpt_help:
        time_str = gpt_help.split("$")[1]

    if date_str and time_str:
        steps["date"] = date_str
        steps["time"] = time_str
        return generate_response(conversation_history, f"L'utilisateur a spÃ©cifiÃ© la date {steps['date']} et l'heure {steps['time']}. Faire un petit rÃ©capitulatif et dire si l'utilisateur est d'accord pour lancer la recherche.")

    elif date_str:
        try:
            datetime.strptime(date_str, "%Y-%m-%d")
            steps["date"] = date_str
            return generate_response(conversation_history, f"L'utilisateur a spÃ©cifiÃ© la date {steps['date']}. Veuillez demander maintenant l'heure exacte de dÃ©part.")
        except ValueError:
            return generate_response(conversation_history, "Je n'ai pas compris la date. Pouvez-vous reformuler, s'il vous plaÃ®t ?")
    elif time_str:
        try:
            datetime.strptime(time_str, "%H:%M:%S")
            steps["time"] = time_str
            return generate_response(conversation_history, f"L'utilisateur a spÃ©cifiÃ© l'heure {steps['time']}. Veuillez demander maintenant la date exacte.")
        except ValueError:
            return generate_response(conversation_history, "Je n'ai pas compris l'heure. Pouvez-vous reformuler, s'il vous plaÃ®t ?")
    else:
        return generate_response(conversation_history, "Je n'ai pas bien compris la date ou l'heure. Pouvez-vous reformuler, s'il vous plaÃ®t ?")


def process_trip_request(steps, session_id, conversation_history):
    """
    Envoie une requÃªte pour rÃ©cupÃ©rer les dÃ©tails du voyage et les formate
    """
    trip_request_data = {
        "origin_name": steps['origin'],
        "destination_name": steps['destination'],
        "date": steps['date'],
        "time": steps['time']
    }
    trip_request = TripRequestModel(**trip_request_data)
    response = get_trip(trip_request)

    if response.get("trip_details"):
        trip_details = response["trip_details"]
        gpt_reply = generate_response(
            conversation_history,
            f"Voici les dÃ©tails du voyage rÃ©cupÃ©rÃ©s: {trip_details}, il faut que l'affichage soit facile Ã  lire pour l'utilisateur, donc formate en Markdown afin que Ã§a soit propre (titre avec niveau, gras, italique, etc.). Propose 3 trajets maximum. Il est important de fournir des informations claires et prÃ©cises pour le voyage demandÃ© (heure de dÃ©part, heure d'arrivÃ©e, correspondances, etc.). Formule une rÃ©ponse polie et engageante avec une suggestion pour un nouveau voyage. Dire que l'utilisateur peut demander une nouvelle recherche car c'est fini pour ce voyage.",
            max_tokens=800
        )

        # RÃ©initialiser les Ã©tapes et l'historique de la conversation
        conversations[session_id] = {
            "steps": {
                "origin": None,
                "destination": None,
                "date": None,
                "time": None,
            },
            "conversation_history": [],
            "count_trip_details": 0
        }

        return gpt_reply

    else:
        conversations[session_id]["count_trip_details"] += 1
        return generate_response(conversation_history, f"Une erreur s'est produite lors de la rÃ©cupÃ©ration des dÃ©tails du voyage. Demande Ã  l'utilisateur s'il veut rÃ©essayer ou arrÃªter le processus. Reponse de la requete: {response.get('response')}.")


async def ask_gpt(user_query: UserQuery):
    """
    Fonction pour gÃ©rer les requÃªtes utilisateur et les rÃ©ponses de GPT pour une conversation sur les transports publics
    """
    session_id = user_query.session_id

    if session_id not in conversations:
        initialize_conversation(session_id)

    user_input = user_query.query
    steps = conversations[session_id]["steps"]
    conversation_history = conversations[session_id]["conversation_history"]

    # Ajouter l'entrÃ©e utilisateur Ã  l'historique
    conversation_history.append({"role": "user", "content": user_input})

    if "stop" in user_input.lower():
        gpt_reply = generate_response(conversation_history, "Merci pour votre visite. N'hÃ©sitez pas Ã  relancer une demande de planification de voyage si vous avez besoin d'aide. Ã€ bientÃ´t ! ğŸ‘‹")
        del conversations[session_id]
        return {"gpt_answer": gpt_reply, "session_id": session_id}

    # Gestion des Ã©tapes de la conversation
    gpt_reply = handle_conversation_steps(user_input, steps, conversation_history)

    # Si toutes les informations sont collectÃ©es
    if all(steps.values()):
        gpt_reply = process_trip_request(steps, session_id, conversation_history)

    # Ajouter la rÃ©ponse de GPT Ã  l'historique
    conversation_history.append({"role": "assistant", "content": gpt_reply})

    return {"gpt_answer": gpt_reply, "session_id": session_id}
